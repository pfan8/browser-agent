/**
 * Think Node
 * 
 * Uses LLM to reason about the current observation and decide on the next action.
 * Implements:
 * - RA-02: LLM-based thinking
 * - RA-06: Loop detection via action signature tracking
 * - RA-08: Rule-based fallback when LLM unavailable
 */

import { ChatAnthropic } from '@langchain/anthropic';
import { HumanMessage, SystemMessage, AIMessage } from '@langchain/core/messages';
import type { AgentState, AgentAction } from '../state';
import { generateId, isRepeatedAction, updateActionSignature } from '../state';
import type { StructuredToolInterface } from '@langchain/core/tools';
import { loadLLMConfig, type LLMConfig } from '../config';

/**
 * Configuration for the think node
 * Can be partial - missing values will be loaded from config file or defaults
 */
export interface ThinkNodeConfig {
  apiKey?: string;
  baseUrl?: string;
  model?: string;
  // Additional LLM parameters (optional)
  temperature?: number;
  topP?: number;
  topK?: number;
  maxTokens?: number;
}

/**
 * Parsed action from LLM response
 */
interface ParsedAction {
  tool: string;
  args: Record<string, unknown>;
  thought: string;
  reasoning: string;
  isComplete: boolean;
  completionMessage?: string;
}

/**
 * Rule patterns for RA-08 fallback
 */
interface RulePattern {
  patterns: RegExp[];
  tool: string;
  extractArgs: (goal: string, match: RegExpMatchArray) => Record<string, unknown>;
}

/**
 * Rule-based patterns for common commands (RA-08)
 */
const RULE_PATTERNS: RulePattern[] = [
  // Navigation rules
  {
    patterns: [
      /(?:navigate|go|open|æ‰“å¼€|è®¿é—®|å¯¼èˆª)\s*(?:to)?\s*(?:the\s*)?(?:url\s*)?[:\s]*["']?([^\s"']+)["']?/i,
      /(?:navigate|go|open)\s+([^\s]+)/i,
    ],
    tool: 'navigate',
    extractArgs: (_, match) => ({ url: match[1] }),
  },
  // Click rules
  {
    patterns: [
      /(?:click|ç‚¹å‡»|æŒ‰)\s*(?:on|the)?\s*["']?([^"']+)["']?/i,
      /click\s+(.+)/i,
    ],
    tool: 'click',
    extractArgs: (_, match) => ({ selector: match[1].trim() }),
  },
  // Type rules - Pattern 1: "type X in Y" (text first, then selector)
  {
    patterns: [
      /(?:type|input|è¾“å…¥|å¡«å†™)\s*["']?([^"']+)["']?\s*(?:in|into|to|åˆ°)\s*["']?([^"']+)["']?/i,
    ],
    tool: 'type',
    extractArgs: (_, match) => {
      // Pattern: "type TEXT in SELECTOR" â†’ match[1]=text, match[2]=selector
      const text = match[1];
      const selector = match[2];
      return { selector: selector.trim(), text: text.trim() };
    },
  },
  // Type rules - Pattern 2: "åœ¨Yè¾“å…¥X" (selector first, then text)
  {
    patterns: [
      /(?:åœ¨|åœ¨.*ä¸­|into)\s*["']?([^"']+)["']?\s*(?:è¾“å…¥|type)\s*["']?([^"']+)["']?/i,
    ],
    tool: 'type',
    extractArgs: (_, match) => {
      // Pattern: "åœ¨SELECTORè¾“å…¥TEXT" â†’ match[1]=selector, match[2]=text
      const selector = match[1];
      const text = match[2];
      return { selector: selector.trim(), text: text.trim() };
    },
  },
  // Press key rules
  {
    patterns: [
      /(?:press|æŒ‰ä¸‹|æŒ‰é”®)\s*(?:the\s*)?["']?(\w+)["']?(?:\s*key)?/i,
    ],
    tool: 'press',
    extractArgs: (_, match) => ({ key: match[1] }),
  },
  // Wait rules - milliseconds (default)
  {
    patterns: [
      /(?:wait|ç­‰å¾…)\s*(?:for)?\s*(\d+)\s*(?:ms|milliseconds|æ¯«ç§’)/i,
    ],
    tool: 'wait',
    extractArgs: (_, match) => {
      const ms = parseInt(match[1], 10);
      return { ms };
    },
  },
  // Wait rules - seconds (explicit conversion)
  {
    patterns: [
      /(?:wait|ç­‰å¾…)\s*(?:for)?\s*(\d+)\s*(?:s|seconds|ç§’)/i,
    ],
    tool: 'wait',
    extractArgs: (_, match) => {
      // Convert seconds to milliseconds
      const ms = parseInt(match[1], 10) * 1000;
      return { ms };
    },
  },
  // Wait rules - bare number defaults to milliseconds
  {
    patterns: [
      /(?:wait|ç­‰å¾…)\s*(?:for)?\s*(\d+)$/i,
    ],
    tool: 'wait',
    extractArgs: (_, match) => {
      const ms = parseInt(match[1], 10);
      return { ms };
    },
  },
  // Screenshot rules
  {
    patterns: [
      /(?:screenshot|æˆªå›¾|capture|æˆªå±)/i,
    ],
    tool: 'screenshot',
    extractArgs: () => ({}),
  },
];

/**
 * Patterns that indicate a chat/greeting message, not a browser task
 */
const CHAT_PATTERNS: RegExp[] = [
  // Greetings
  /^(ä½ å¥½|æ‚¨å¥½|hi|hello|hey|å—¨|å“ˆå–½|æ—©ä¸Šå¥½|ä¸‹åˆå¥½|æ™šä¸Šå¥½|good\s*(morning|afternoon|evening))[\s!ï¼ã€‚.?ï¼Ÿ]*$/i,
  // Questions about the agent
  /^(ä½ æ˜¯è°|who are you|what are you|ä½ èƒ½åšä»€ä¹ˆ|what can you do|help|å¸®åŠ©)[\s!ï¼ã€‚.?ï¼Ÿ]*$/i,
  // Thanks
  /^(è°¢è°¢|thanks|thank you|thx|æ„Ÿè°¢)[\s!ï¼ã€‚.?ï¼Ÿ]*$/i,
  // Goodbye
  /^(å†è§|æ‹œæ‹œ|bye|goodbye|see you)[\s!ï¼ã€‚.?ï¼Ÿ]*$/i,
  // Simple acknowledgments
  /^(å¥½çš„|ok|okay|å¥½|å—¯|æ˜¯çš„|yes|no|ä¸|å¯¹|æ²¡é—®é¢˜)[\s!ï¼ã€‚.?ï¼Ÿ]*$/i,
  // Very short messages (likely not browser commands)
  /^.{1,5}$/,
];

/**
 * Check if the goal is a chat message rather than a browser task
 */
function isChatMessage(goal: string): boolean {
  const normalized = goal.trim();
  return CHAT_PATTERNS.some(pattern => pattern.test(normalized));
}

/**
 * Generate a friendly chat response based on the message type
 */
function getChatResponse(goal: string): string {
  const normalized = goal.trim().toLowerCase();
  
  if (/^(ä½ å¥½|æ‚¨å¥½|hi|hello|hey|å—¨|å“ˆå–½)/i.test(normalized)) {
    return 'ä½ å¥½ï¼æˆ‘æ˜¯æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠ©æ‰‹ã€‚è¯·å‘Šè¯‰æˆ‘ä½ æƒ³è¦æ‰§è¡Œçš„æµè§ˆå™¨æ“ä½œï¼Œä¾‹å¦‚ï¼š\n- "æ‰“å¼€ https://google.com"\n- "ç‚¹å‡»æœç´¢æŒ‰é’®"\n- "åœ¨è¾“å…¥æ¡†è¾“å…¥ hello"';
  }
  if (/^(æ—©ä¸Šå¥½|good\s*morning)/i.test(normalized)) {
    return 'æ—©ä¸Šå¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„æµè§ˆå™¨æ“ä½œå—ï¼Ÿ';
  }
  if (/^(ä¸‹åˆå¥½|good\s*afternoon)/i.test(normalized)) {
    return 'ä¸‹åˆå¥½ï¼éœ€è¦æˆ‘å¸®ä½ æ‰§è¡Œä»€ä¹ˆæµè§ˆå™¨æ“ä½œï¼Ÿ';
  }
  if (/^(æ™šä¸Šå¥½|good\s*evening)/i.test(normalized)) {
    return 'æ™šä¸Šå¥½ï¼è¯·å‘Šè¯‰æˆ‘ä½ æƒ³è¦æ‰§è¡Œçš„æ“ä½œã€‚';
  }
  if (/^(ä½ æ˜¯è°|who are you|what are you)/i.test(normalized)) {
    return 'æˆ‘æ˜¯æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ æ§åˆ¶æµè§ˆå™¨æ‰§è¡Œå„ç§æ“ä½œï¼Œå¦‚å¯¼èˆªã€ç‚¹å‡»ã€è¾“å…¥æ–‡å­—ç­‰ã€‚';
  }
  if (/^(ä½ èƒ½åšä»€ä¹ˆ|what can you do|help|å¸®åŠ©)/i.test(normalized)) {
    return 'æˆ‘å¯ä»¥å¸®ä½ ï¼š\n- å¯¼èˆªåˆ°ç½‘å€ (ä¾‹å¦‚: "æ‰“å¼€ google.com")\n- ç‚¹å‡»å…ƒç´  (ä¾‹å¦‚: "ç‚¹å‡»ç™»å½•æŒ‰é’®")\n- è¾“å…¥æ–‡å­— (ä¾‹å¦‚: "åœ¨æœç´¢æ¡†è¾“å…¥ hello")\n- æˆªå›¾ (ä¾‹å¦‚: "æˆªå›¾")\n- ç­‰å¾… (ä¾‹å¦‚: "ç­‰å¾… 2 ç§’")';
  }
  if (/^(è°¢è°¢|thanks|thank you)/i.test(normalized)) {
    return 'ä¸å®¢æ°”ï¼è¿˜æœ‰ä»€ä¹ˆéœ€è¦å¸®å¿™çš„å—ï¼Ÿ';
  }
  if (/^(å†è§|æ‹œæ‹œ|bye|goodbye)/i.test(normalized)) {
    return 'å†è§ï¼éšæ—¶å¯ä»¥æ‰¾æˆ‘å¸®å¿™ã€‚';
  }
  
  return `æ”¶åˆ°æ¶ˆæ¯: "${goal}"ã€‚å¦‚æœä½ æƒ³æ‰§è¡Œæµè§ˆå™¨æ“ä½œï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“çš„ä»»åŠ¡ã€‚`;
}

/**
 * Apply rule-based thinking as fallback (RA-08)
 */
function applyRuleBasedThinking(goal: string): ParsedAction | null {
  const normalizedGoal = goal.trim().toLowerCase();
  
  // First, check if this is a chat/greeting message (not a browser task)
  if (isChatMessage(goal)) {
    const response = getChatResponse(goal);
    return {
      tool: '',
      args: {},
      thought: 'This is a chat message, not a browser operation request',
      reasoning: 'Detected greeting or chat pattern',
      isComplete: true,
      completionMessage: response,
    };
  }
  
  // Check browser operation patterns
  for (const rule of RULE_PATTERNS) {
    for (const pattern of rule.patterns) {
      const match = goal.match(pattern);
      if (match) {
        const args = rule.extractArgs(goal, match);
        return {
          tool: rule.tool,
          args,
          thought: `[Rule-based] Matched pattern for ${rule.tool}`,
          reasoning: `Applied rule pattern: ${pattern.source}`,
          isComplete: false,
        };
      }
    }
  }
  
  // Check for completion keywords
  if (/(?:done|complete|finished|å®Œæˆ|ç»“æŸ)/i.test(normalizedGoal)) {
    return {
      tool: '',
      args: {},
      thought: 'Task appears to be complete',
      reasoning: 'Detected completion keyword',
      isComplete: true,
      completionMessage: 'Task completed based on user input',
    };
  }
  
  return null;
}

/**
 * Creates a think node that uses LLM to decide actions (RA-02, RA-06, RA-08)
 */
export function createThinkNode(config: ThinkNodeConfig, tools: StructuredToolInterface[]) {
  // Load full config from file, env, and runtime overrides
  const llmConfig = loadLLMConfig({
    apiKey: config.apiKey,
    baseUrl: config.baseUrl,
    model: config.model,
    temperature: config.temperature,
    topP: config.topP,
    topK: config.topK,
    maxTokens: config.maxTokens,
  });
  
  // Check if LLM is configured (apiKey from config file, env, or runtime)
  const hasLlm = !!llmConfig.apiKey;
  
  let llm: ChatAnthropic | null = null;
  if (hasLlm) {
    console.log(`[ThinkNode] Initializing LLM: model=${llmConfig.model}, baseUrl=${llmConfig.baseUrl || 'default'}`);
    
    // Build LLM options, only including defined values
    const llmOptions: Record<string, unknown> = {
      anthropicApiKey: llmConfig.apiKey,
      modelName: llmConfig.model,
    };

    // Optional parameters
    if (llmConfig.temperature !== undefined) {
      llmOptions.temperature = llmConfig.temperature;
    }
    if (llmConfig.topP !== undefined) {
      llmOptions.topP = llmConfig.topP;
    }
    if (llmConfig.baseUrl) {
      llmOptions.anthropicApiUrl = llmConfig.baseUrl;
    }
    if (llmConfig.topK !== undefined) {
      llmOptions.topK = llmConfig.topK;
    }
    if (llmConfig.maxTokens !== undefined) {
      llmOptions.maxOutputTokens = llmConfig.maxTokens;
    }

    console.log('[ThinkNode] LLM options:', llmOptions);
    
    llm = new ChatAnthropic(llmOptions);
  }

  // Build tool descriptions for the system prompt
  const toolDescriptions = tools.map(tool => {
    return `- ${tool.name}: ${tool.description}`;
  }).join('\n');

  const systemPrompt = `You are a browser automation agent. Your task is to help users accomplish tasks in a web browser.

You have access to the following tools:
${toolDescriptions}

Based on the current observation (page URL, title, and content), decide what action to take next.

IMPORTANT RULES:
1. Always respond with a valid JSON object
2. Think step by step about what needs to be done
3. If the task is complete, set "isComplete" to true and provide a "completionMessage"
4. Use the most appropriate tool for each action
5. Be precise with selectors - prefer data-testid, id, or aria-label over text content
6. **CRITICAL**: If the user's message is a greeting (e.g., "ä½ å¥½", "hi", "hello") or a chat message 
   that does NOT require browser operations, respond with isComplete=true and a friendly reply.
   Do NOT try to navigate or perform browser actions for simple greetings/chat.
7. Only perform browser operations when the user explicitly requests actions like:
   - Navigation: "æ‰“å¼€", "open", "go to", "navigate"
   - Clicking: "ç‚¹å‡»", "click"
   - Typing: "è¾“å…¥", "type", "fill"
   - etc.

Response format for BROWSER OPERATIONS:
{
  "thought": "Your reasoning about the current state",
  "tool": "tool_name",
  "args": { "arg1": "value1" },
  "reasoning": "Why you chose this action",
  "isComplete": false
}

Response format for COMPLETED TASKS or CHAT MESSAGES:
{
  "thought": "The task has been completed / This is a greeting",
  "isComplete": true,
  "completionMessage": "Summary or friendly reply"
}`;

  return async (state: AgentState): Promise<Partial<AgentState>> => {
    console.log('[ThinkNode] Reasoning about next action...');
    
    try {
      // Build context from observation
      const observation = state.observation;
      if (!observation) {
        return {
          status: 'error',
          error: 'No observation available',
        };
      }

      let parsed: ParsedAction;
      let responseText = '';

      // RA-08: Try rule-based fallback first if LLM not available or flagged
      if (!hasLlm || state.useFallbackRules) {
        console.log('[ThinkNode] Using rule-based fallback (RA-08)');
        const ruleParsed = applyRuleBasedThinking(state.goal);
        
        if (ruleParsed) {
          parsed = ruleParsed;
          responseText = JSON.stringify(ruleParsed);
        } else {
          // No matching rule, cannot proceed
          return {
            status: 'error',
            error: 'No matching rule found and LLM not available',
            useFallbackRules: true,
          };
        }
      } else {
        // RA-02: Use LLM for thinking
        try {
      // Build the user message with current context
      const userMessage = `
Goal: ${state.goal}
${state.originalGoal !== state.goal ? `Original Goal: ${state.originalGoal}` : ''}

Current Page:
- URL: ${observation.url}
- Title: ${observation.title}
- Load State: ${observation.loadState || 'unknown'}
${observation.hasModalOverlay ? '- WARNING: Modal overlay detected' : ''}
${observation.hasLoadingIndicator ? '- WARNING: Page is still loading' : ''}

Page Content (truncated):
${observation.content?.slice(0, 5000) || 'No content available'}

Previous Actions (last 5):
${state.actionHistory.slice(-5).map(a => `- ${a.tool}(${JSON.stringify(a.args)}) -> ${a.result?.success ? 'success' : 'failed: ' + a.result?.error}`).join('\n') || 'None'}

Completed Steps: ${state.completedSteps.length}
Iteration: ${state.iterationCount}

What should be the next action? Respond with a valid JSON object.`;

      // Call LLM
      const messages = [
        new SystemMessage(systemPrompt),
        ...state.messages,
        new HumanMessage(userMessage),
      ];

          const response = await llm!.invoke(messages);
          responseText = typeof response.content === 'string' 
        ? response.content 
        : JSON.stringify(response.content);

      console.log('[ThinkNode] LLM response:', responseText.slice(0, 200));

      // Parse the response
          const parseResult = parseThinkResponse(responseText);
          
          // Handle parsing failure
          if (!parseResult.parsed) {
            console.error('[ThinkNode] Parse error:', parseResult.error);
            
            // Count consecutive parse failures
            const parseFailures = (state.consecutiveFailures || 0) + 1;
            
            // If we've failed to parse multiple times, give up with a friendly error
            if (parseFailures >= 2) {
              return {
                status: 'error',
                error: parseResult.error,
                isComplete: true,
                result: `âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥\n\nğŸ“‹ å¤±è´¥åŸå› : AI å“åº”æ ¼å¼è§£æå¤šæ¬¡å¤±è´¥\n\nğŸ’¡ å»ºè®®: è¯·å°è¯•ç”¨æ›´ç®€å•æ˜ç¡®çš„è¯­è¨€æè¿°ä»»åŠ¡ï¼Œä¾‹å¦‚:\n  - "æ‰“å¼€ google.com"\n  - "ç‚¹å‡»ç™»å½•æŒ‰é’®"\n  - "åœ¨æœç´¢æ¡†è¾“å…¥ hello"\n\nğŸ“ AI éƒ¨åˆ†å“åº”: ${parseResult.partialContent || 'N/A'}`,
                consecutiveFailures: parseFailures,
              };
            }
            
            // Try rule-based fallback
            const ruleParsed = applyRuleBasedThinking(state.goal);
            if (ruleParsed) {
              parsed = ruleParsed;
            } else {
              return {
                status: 'observing', // Go back to observe and try again
                consecutiveFailures: parseFailures,
              };
            }
          } else {
            parsed = parseResult.parsed;
          }
        } catch (llmError) {
          // RA-08: Fall back to rules on LLM error
          console.warn('[ThinkNode] LLM error, falling back to rules:', llmError);
          const ruleParsed = applyRuleBasedThinking(state.goal);
          
          if (ruleParsed) {
            parsed = ruleParsed;
            responseText = JSON.stringify(ruleParsed);
          } else {
            return {
              status: 'error',
              error: `LLM failed: ${llmError instanceof Error ? llmError.message : llmError}`,
              isComplete: true,
              result: `âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥\n\nğŸ“‹ å¤±è´¥åŸå› : AI æœåŠ¡è°ƒç”¨å¤±è´¥\n\nğŸ’¡ å»ºè®®: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API é…ç½®ï¼Œæˆ–ç¨åé‡è¯•`,
              useFallbackRules: true,
              consecutiveFailures: state.consecutiveFailures + 1,
            };
          }
        }
      }

      if (parsed.isComplete) {
        console.log('[ThinkNode] Task complete:', parsed.completionMessage);
        return {
          status: 'complete',
          isComplete: true,
          result: parsed.completionMessage || 'âœ… ä»»åŠ¡å®Œæˆ',
          messages: hasLlm ? [...state.messages, new AIMessage(responseText)] : state.messages,
        };
      }

      // RA-06: Check for repeated action (loop detection)
      if (isRepeatedAction(state.actionSignatures, parsed.tool, parsed.args, 3)) {
        console.warn('[ThinkNode] RA-06: Repeated action detected, possible loop');
        return {
          status: 'error',
          error: 'Detected repeated action loop - same action attempted 3+ times',
          loopDetected: true,
          isComplete: true,
          result: 'Task terminated due to detected infinite loop',
        };
      }

      // Update action signatures for loop tracking
      const newSignatures = updateActionSignature(
        state.actionSignatures,
        parsed.tool,
        parsed.args
      );

      // Create action record
      const action: AgentAction = {
        id: generateId('action'),
        tool: parsed.tool,
        args: parsed.args,
        thought: parsed.thought,
        reasoning: parsed.reasoning,
        timestamp: new Date().toISOString(),
        retryCount: 0,
        maxRetries: 3,
      };

      console.log(`[ThinkNode] Decided action: ${action.tool}(${JSON.stringify(action.args)})`);

      return {
        status: 'thinking',
        actionHistory: [action],
        actionSignatures: newSignatures,
        messages: hasLlm ? [...state.messages, new AIMessage(responseText)] : state.messages,
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      console.error('[ThinkNode] Error:', errorMessage);
      
      return {
        status: 'error',
        error: `Think failed: ${errorMessage}`,
        consecutiveFailures: state.consecutiveFailures + 1,
      };
    }
  };
}

/**
 * Result type for parsing - includes error info
 */
interface ParseResult {
  parsed: ParsedAction | null;
  error: string | null;
  partialContent: string | null;
}

/**
 * Parse the LLM response into a structured action
 * Returns error info if parsing fails
 */
function parseThinkResponse(response: string): ParseResult {
  try {
    // Try to extract JSON from the response
    const jsonMatch = response.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      // Maybe the LLM responded with natural language instead of JSON
      // Try to detect if it's a completion message
      if (response.includes('complete') || response.includes('å®Œæˆ') || 
          response.includes('done') || response.includes('finished')) {
        return {
          parsed: {
            tool: '',
            args: {},
            thought: response,
            reasoning: 'LLM indicated task completion',
            isComplete: true,
            completionMessage: response.slice(0, 500),
          },
          error: null,
          partialContent: null,
        };
      }
      
      return {
        parsed: null,
        error: 'No JSON found in response',
        partialContent: response.slice(0, 200),
      };
    }

    const parsed = JSON.parse(jsonMatch[0]);

    return {
      parsed: {
      tool: parsed.tool || '',
      args: parsed.args || {},
      thought: parsed.thought || '',
      reasoning: parsed.reasoning || '',
      isComplete: parsed.isComplete === true,
      completionMessage: parsed.completionMessage,
      },
      error: null,
      partialContent: null,
    };
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : 'Unknown parse error';
    console.error('[ThinkNode] Failed to parse response:', error);
    
    // Try to extract partial info from truncated response
    const thoughtMatch = response.match(/"thought"\s*:\s*"([^"]+)/);
    const partialThought = thoughtMatch ? thoughtMatch[1] : null;
    
    return {
      parsed: null,
      error: `JSON parsing error: ${errorMsg}`,
      partialContent: partialThought || response.slice(0, 200),
    };
  }
}

